{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "des_pts = np.array([[200,100], [800,100], [200,700], [800,700]])\n",
    "des_cm = np.array([[200,100], [383,100], [200,283], [383,283]])\n",
    "src_pts = np.array([[516,22], [971,182], [206,392], [730,685]])\n",
    "\n",
    "h, status = cv2.findHomography(src_pts, des_cm)\n",
    "np.save('h_cm.npy', h, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### live perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time\n",
    "import numpy as np\n",
    "vid = cv2.VideoCapture(-1)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "time.sleep(2)\n",
    "h = np.load('h_from_board.npy')\n",
    "while True:\n",
    "    _, img = vid.read()\n",
    "    img = cv2.circle(img, (500, 500), 1, color=(0,0,255), thickness=9)\n",
    "    warp_img = cv2.warpPerspective(img, h, (img.shape[1],img.shape[0]))\n",
    "    cv2.imshow('img', warp_img)\n",
    "   #  cv2.imwrite('template.jpg', img)\n",
    "   #  if True:\n",
    "   #     break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "      break\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIVE FEED WITH DOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23570489883422852tected on shoe\n",
      "0.11082768440246582\n",
      "0.10860681533813477\n",
      "0.13283014297485352\n",
      "0.11230254173278809\n",
      "0.13887333869934082\n",
      "0.12182855606079102\n",
      "0.12743306159973145\n",
      "0.14894795417785645\n",
      "0.14778685569763184\n",
      "0.13759231567382812\n",
      "0.13811373710632324\n",
      "0.1384279727935791\n",
      "0.16225862503051758\n",
      "0.14025115966796875\n",
      "0.12518072128295898\n",
      "0.16005492210388184\n",
      "0.14013433456420898\n",
      "0.15975189208984375\n",
      "0.1237020492553711\n",
      "0.1411583423614502\n",
      "0.14600491523742676\n",
      "0.11991691589355469\n",
      "0.14040136337280273\n",
      "0.16180419921875\n",
      "0.15850830078125\n",
      "0.147810697555542\n",
      "0.14742684364318848\n",
      "0.1436600685119629\n",
      "0.1376664638519287\n",
      "0.14150571823120117\n",
      "0.13904142379760742\n",
      "0.15182161331176758\n",
      "0.14049911499023438\n",
      "0.14096307754516602\n",
      "0.12862157821655273\n",
      "0.14337611198425293\n",
      "0.12260007858276367\n",
      "0.12872099876403809\n",
      "0.15378952026367188\n",
      "0.1653439998626709\n",
      "0.1458444595336914\n",
      "0.13367438316345215\n",
      "0.14350366592407227\n",
      "0.11677980422973633\n",
      "0.1110074520111084\n",
      "0.14565634727478027\n",
      "0.12224817276000977\n",
      "0.12016415596008301\n",
      "0.13680481910705566\n",
      "0.14071941375732422\n",
      "0.1342606544494629\n",
      "0.1170358657836914\n",
      "0.1547863483428955\n",
      "0.16524600982666016\n",
      "0.14122343063354492\n",
      "0.13381433486938477\n",
      "0.1324474811553955\n",
      "0.13837742805480957\n",
      "0.13434600830078125\n",
      "0.13820624351501465\n",
      "0.15771842002868652\n",
      "0.15752553939819336\n",
      "0.12392067909240723\n",
      "0.13260269165039062\n",
      "0.15082120895385742\n",
      "0.1432785987854004\n",
      "0.15128874778747559\n",
      "0.14038515090942383\n",
      "0.10906481742858887tected on shoe\n",
      "0.12790822982788086\n",
      "0.14777255058288574\n",
      "0.14753007888793945\n",
      "0.14319872856140137\n",
      "0.1406848430633545\n",
      "0.14797163009643555\n",
      "0.12818551063537598\n",
      "0.13866829872131348\n",
      "0.13691163063049316\n",
      "0.13504695892333984\n",
      "0.11240696907043457\n",
      "0.14110350608825684\n",
      "0.11249899864196777\n",
      "0.12025952339172363\n",
      "0.11327457427978516\n",
      "0.1290283203125\n",
      "0.1184535026550293\n",
      "0.14910888671875\n",
      "0.1299300193786621\n",
      "0.1327366828918457\n",
      "0.12687373161315918\n",
      "0.136061429977417\n",
      "0.13762998580932617\n",
      "0.12239623069763184\n",
      "0.11702871322631836\n",
      "0.11236405372619629\n",
      "0.1018531322479248\n",
      "0.13152575492858887tected on shoe\n",
      "0.14342975616455078tected on shoe\n",
      "0.12407946586608887tected on shoe\n",
      "0.11281967163085938\n",
      "0.14037847518920898\n",
      "No box landmarks detected on shoe\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No box landmarks detected on shoe\r"
     ]
    }
   ],
   "source": [
    "import cv2, time\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "mp_objectron = mp.solutions.objectron\n",
    "vid = cv2.VideoCapture(0)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "iterations = [1, 2, 5, 6]\n",
    "h = np.load('h.npy')\n",
    "temp_img = cv2.imread('template.jpg')\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    _, img = vid.read()\n",
    "    with mp_objectron.Objectron(static_image_mode=True, max_num_objects=6, min_detection_confidence=0.5, model_name='Shoe') as objectron:\n",
    "   \n",
    "      results = objectron.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "      if not results.detected_objects:\n",
    "        print('No box landmarks detected on shoe', end= '\\r')\n",
    "        continue\n",
    "      #print('Box landmarks of shoe:')\n",
    "      ann_img = img.copy()\n",
    "      temp_img_copy = temp_img.copy()\n",
    "      display_img = temp_img_copy\n",
    "      for detected_object in results.detected_objects:\n",
    "        for i in iterations:\n",
    "          x = int(detected_object.landmarks_2d.landmark[i].x * img.shape[1])\n",
    "          y = int(detected_object.landmarks_2d.landmark[i].y * img.shape[0])\n",
    "          display_img = cv2.circle(display_img, (x,y), 1, color=(0, 0, 255), thickness=5)\n",
    "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "      warp_img = cv2.warpPerspective(display_img, h, (img.shape[1],img.shape[0]))\n",
    "      cv2.imshow('img', warp_img)\n",
    "    end_time = time.time()\n",
    "    print(end_time - start_time)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LIVE FEED WITH CIRCLE AND DIRECTION - SINGLE PERSON ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no detected objects\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no detected objects\r"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import mediapipe as mp\n",
    "\n",
    "#img = cv2.imread('shoe.png')\n",
    "#img = cv2.imread('/home/hameed/Downloads/shoes.jpeg')\n",
    "vid = cv2.VideoCapture(-1)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "time.sleep(2)\n",
    "\n",
    "def midpoint(x1, y1, x2, y2):\n",
    "    return ((x1 + x2)/2, (y1 + y2)/2)\n",
    "\n",
    "def point_transform(p, h):\n",
    "    p = np.array(p, dtype='float32').reshape((1,1,2))\n",
    "    p_out = cv2.perspectiveTransform(p, h)[0,0,:]\n",
    "    return p_out\n",
    "\n",
    "\n",
    "mp_objectron = mp.solutions.objectron\n",
    "\n",
    "fx, fy = (1.0, 1.0)\n",
    "px, py = (0.0, 0.0)\n",
    "iterations = [1, 2, 5, 6]\n",
    "h = np.load('h_from_board.npy')\n",
    "\n",
    "\n",
    "axis_world = np.float32([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "t_end = time.time() + 60 * 15\n",
    "while time.time() < t_end:\n",
    "    _, img = vid.read()\n",
    "    objectron = mp_objectron.Objectron(mp_objectron.Objectron(static_image_mode=True, max_num_objects=5, min_detection_confidence=0.5, model_name='Shoe'))\n",
    "    results = objectron.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ann_img = img.copy()\n",
    "    #warp_img = img.copy()\n",
    "    x = []\n",
    "    y = []\n",
    "    z_axis = []\n",
    "    if not results.detected_objects:\n",
    "        print('no detected objects', end='\\r')\n",
    "        continue\n",
    "    for obj in results.detected_objects:\n",
    "        \n",
    "        x.append(int(obj.landmarks_2d.landmark[0].x * img.shape[1]))\n",
    "        y.append(int(obj.landmarks_2d.landmark[0].y * img.shape[0]))\n",
    "\n",
    "        axis_cam = np.matmul(obj.rotation, 0.1 * axis_world.T).T + obj.translation\n",
    "        x_ori = axis_cam[..., 0]\n",
    "        y_ori = axis_cam[..., 1]\n",
    "        z_ori = axis_cam[..., 2]\n",
    "    # Project 3D points to NDC space.\n",
    "        x_ndc = np.clip(-fx * x_ori / (z_ori + 1e-5) + px, -1., 1.)\n",
    "        y_ndc = np.clip(-fy * y_ori / (z_ori + 1e-5) + py, -1., 1.)\n",
    "    # Convert from NDC space to image space.\n",
    "        x_im = np.int32((1 + x_ndc) * 0.5 * img.shape[1])\n",
    "        y_im = np.int32((1 - y_ndc) * 0.5 * img.shape[0])\n",
    "        z_axis.append((x_im[3], y_im[3]))\n",
    "\n",
    "    try:\n",
    "        x, y = midpoint(x[0], y[0], x[1], y[1])\n",
    "        x, y = point_transform((x,y), h)\n",
    "        z0, z1 = midpoint(z_axis[0][0], z_axis[0][1], z_axis[1][0], z_axis[1][1])\n",
    "        z0, z1 = point_transform((z0, z1), h)\n",
    "\n",
    "        warp_img = cv2.warpPerspective(ann_img, h, (img.shape[1],img.shape[0]))\n",
    "        warp_img = cv2.circle(warp_img, (int(x), int(y)), radius=100, color=(0, 0, 255), thickness=5)\n",
    "        warp_img = cv2.arrowedLine(warp_img, (int(x), int(y)), (int(z0), int(z1)), color=(0, 128, 0), thickness=3, tipLength=0.5)\n",
    "    except:\n",
    "        print('not enough points', end='\\r')\n",
    "\n",
    "    try:\n",
    "        cv2.imshow('ann_img', warp_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    except:\n",
    "        print('wait', end='\\r')\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LIVE FEED WITH CIRCLE AND DIRECTION - 2 PERSONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not enough pointsts\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough pointsts\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough pointsts\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "not enough points\n",
      "no detected objects\r"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "#img = cv2.imread('shoe.png')\n",
    "#img = cv2.imread('/home/hameed/Downloads/shoes.jpeg')\n",
    "vid = cv2.VideoCapture(-1)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "def point_transform(p, h):\n",
    "    p = np.array(p, dtype='float32').reshape((1,1,2))\n",
    "    p_out = cv2.perspectiveTransform(p, h)[0,0,:]\n",
    "    return p_out\n",
    "\n",
    "def midpoint(center, pair):\n",
    "    x1 = center[pair[0]][0]\n",
    "    x2 = center[pair[1]][0]\n",
    "    y1 = center[pair[0]][1]\n",
    "    y2 = center[pair[0]][1]\n",
    "    return ((x1 + x2)/2, (y1 + y2)/2)\n",
    "\n",
    "def fetch_value(obj_index):\n",
    "    return {\n",
    "        0 : (0,1),\n",
    "        1 : (0,2),\n",
    "        2 : (0,3),\n",
    "        3 : (1,2),\n",
    "        4 : (1,3),\n",
    "        5 : (2,3)\n",
    "    }[obj_index]\n",
    "\n",
    "mp_objectron = mp.solutions.objectron\n",
    "\n",
    "fx, fy = (1.0, 1.0)\n",
    "px, py = (0.0, 0.0)\n",
    "iterations = [1, 2, 5, 6]\n",
    "h = np.load('h_from_board.npy')\n",
    "\n",
    "\n",
    "axis_world = np.float32([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "t_end = time.time() + 60 * 15\n",
    "while time.time() < t_end:\n",
    "    _, img = vid.read()\n",
    "    objectron = mp_objectron.Objectron(mp_objectron.Objectron(static_image_mode=True, max_num_objects=5, min_detection_confidence=0.5, model_name='Shoe'))\n",
    "    results = objectron.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ann_img = img.copy()\n",
    "    #warp_img = img.copy()\n",
    "    center = []\n",
    "    z_axis = []\n",
    "    if not results.detected_objects:\n",
    "        print('no detected objects', end='\\r')\n",
    "        continue\n",
    "    for obj in results.detected_objects:\n",
    "        \n",
    "        x = (int(obj.landmarks_2d.landmark[0].x * img.shape[1]))\n",
    "        y = (int(obj.landmarks_2d.landmark[0].y * img.shape[0]))\n",
    "        center.append((x,y))\n",
    "\n",
    "        axis_cam = np.matmul(obj.rotation, 0.1 * axis_world.T).T + obj.translation\n",
    "        x_ori = axis_cam[..., 0]\n",
    "        y_ori = axis_cam[..., 1]\n",
    "        z_ori = axis_cam[..., 2]\n",
    "    # Project 3D points to NDC space.\n",
    "        x_ndc = np.clip(-fx * x_ori / (z_ori + 1e-5) + px, -1., 1.)\n",
    "        y_ndc = np.clip(-fy * y_ori / (z_ori + 1e-5) + py, -1., 1.)\n",
    "    # Convert from NDC space to image space.\n",
    "        x_im = np.int32((1 + x_ndc) * 0.5 * img.shape[1])\n",
    "        y_im = np.int32((1 - y_ndc) * 0.5 * img.shape[0])\n",
    "        z_axis.append((x_im[3], y_im[3]))\n",
    "\n",
    "    comb = combinations(center, 2)\n",
    "    comb = list(comb)\n",
    "    dist = []\n",
    "    try:\n",
    "        for i in range(len(comb)):\n",
    "\n",
    "            p1, p2 = comb[i]\n",
    "            dist.append(math.dist(p1, p2))\n",
    "\n",
    "        sorted = dist.copy()\n",
    "        sorted.sort()\n",
    "        obj_index = dist.index(sorted[0]), dist.index(sorted[1])\n",
    "        pairs = fetch_value(obj_index[0]), fetch_value(obj_index[1])\n",
    "        #second_pair = fetch_value(obj_index[1])\n",
    "        for pair in pairs:\n",
    "            x, y = midpoint(center, pair)\n",
    "            z0, z1 = midpoint(z_axis, pair)\n",
    "            cv2.circle(ann_img, (int(x), int(y)), radius=60, color=(0, 0, 255), thickness=5)\n",
    "            cv2.arrowedLine(ann_img, (int(x), int(y)), (int(z0), int(z1)), color=(0, 128, 0), thickness=3, tipLength=3)\n",
    "        cv2.imshow('img', ann_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        print('not enough points', end='\\r')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(788, 280), (693, 281)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_transform(p, h):\n",
    "    p = np.array(p, dtype='float32').reshape((1,1,2))\n",
    "    p_out = cv2.perspectiveTransform(p, h)[0,0,:]\n",
    "    return p_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(387.8386, 613.14435)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b = point_transform((400,400), h)\n",
    "a, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live feed, multiple people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from itertools import combinations\n",
    "import mediapipe as mp\n",
    "import math\n",
    "\n",
    "#img = cv2.imread('shoe.png')\n",
    "#img = cv2.imread('/home/hameed/Downloads/shoes.jpeg')\n",
    "vid = cv2.VideoCapture(-1)\n",
    "vid.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "vid.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "def point_transform(p, h):\n",
    "    p = np.array(p, dtype='float32').reshape((1,1,2))\n",
    "    p_out = cv2.perspectiveTransform(p, h)[0,0,:]\n",
    "    return p_out\n",
    "\n",
    "def midpoint(center, pair):\n",
    "    x1 = center[pair[0]][0]\n",
    "    x2 = center[pair[1]][0]\n",
    "    y1 = center[pair[0]][1]\n",
    "    y2 = center[pair[0]][1]\n",
    "    return ((x1 + x2)/2, (y1 + y2)/2)\n",
    "\n",
    "def fetch_value(obj_index):\n",
    "    return {\n",
    "        0 : (0,1),\n",
    "        1 : (0,2),\n",
    "        2 : (0,3),\n",
    "        3 : (0,4),\n",
    "        4 : (0,5),\n",
    "        5 : (1,2),\n",
    "        6 : (1,3),\n",
    "        7 : (1,4),\n",
    "        8 : (1,5),\n",
    "        9 : (2,3),\n",
    "        10 : (2,4),\n",
    "        11: (2,5),\n",
    "        12 : (3,4),\n",
    "        13 : (3,5),\n",
    "        14 : (4,5),\n",
    "    }[obj_index]\n",
    "\n",
    "mp_objectron = mp.solutions.objectron\n",
    "\n",
    "fx, fy = (1.0, 1.0)\n",
    "px, py = (0.0, 0.0)\n",
    "iterations = [1, 2, 5, 6]\n",
    "h = np.load('h_from_board.npy')\n",
    "\n",
    "\n",
    "axis_world = np.float32([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "\n",
    "t_end = time.time() + 60 * 15\n",
    "while time.time() < t_end:\n",
    "    _, img = vid.read()\n",
    "    objectron = mp_objectron.Objectron(mp_objectron.Objectron(static_image_mode=True, max_num_objects=5, min_detection_confidence=0.5, model_name='Shoe'))\n",
    "    results = objectron.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ann_img = img.copy()\n",
    "    #warp_img = img.copy()\n",
    "    center = []\n",
    "    z_axis = []\n",
    "    if not results.detected_objects:\n",
    "        print('no detected objects', end='\\r')\n",
    "        continue\n",
    "    for obj in results.detected_objects:\n",
    "        \n",
    "        x = (int(obj.landmarks_2d.landmark[0].x * img.shape[1]))\n",
    "        y = (int(obj.landmarks_2d.landmark[0].y * img.shape[0]))\n",
    "        center.append((x,y))\n",
    "\n",
    "        axis_cam = np.matmul(obj.rotation, 0.1 * axis_world.T).T + obj.translation\n",
    "        x_ori = axis_cam[..., 0]\n",
    "        y_ori = axis_cam[..., 1]\n",
    "        z_ori = axis_cam[..., 2]\n",
    "    # Project 3D points to NDC space.\n",
    "        x_ndc = np.clip(-fx * x_ori / (z_ori + 1e-5) + px, -1., 1.)\n",
    "        y_ndc = np.clip(-fy * y_ori / (z_ori + 1e-5) + py, -1., 1.)\n",
    "    # Convert from NDC space to image space.\n",
    "        x_im = np.int32((1 + x_ndc) * 0.5 * img.shape[1])\n",
    "        y_im = np.int32((1 - y_ndc) * 0.5 * img.shape[0])\n",
    "        z_axis.append((x_im[3], y_im[3]))\n",
    "\n",
    "    comb = combinations(center, 2)\n",
    "    comb = list(comb)\n",
    "    dist = []\n",
    "    try:\n",
    "        for i in range(len(comb)):\n",
    "\n",
    "            p1, p2 = comb[i]\n",
    "            dist.append(math.dist(p1, p2))\n",
    "\n",
    "        sorted = dist.copy()\n",
    "        sorted.sort()\n",
    "        obj_index = dist.index(sorted[0]), dist.index(sorted[1])\n",
    "        pairs = fetch_value(obj_index[0]), fetch_value(obj_index[1]), fetch_value(obj_index[2])\n",
    "        #second_pair = fetch_value(obj_index[1])\n",
    "        for pair in pairs:\n",
    "            x, y = midpoint(center, pair)\n",
    "            z0, z1 = midpoint(z_axis, pair)\n",
    "            cv2.circle(ann_img, (int(x), int(y)), radius=60, color=(0, 0, 255), thickness=5)\n",
    "            cv2.arrowedLine(ann_img, (int(x), int(y)), (int(z0), int(z1)), color=(0, 128, 0), thickness=3, tipLength=3)\n",
    "        cv2.imshow('img', ann_img)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    \n",
    "    except:\n",
    "        print('not enough points', end='\\r')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "vid.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
